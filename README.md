# üñºÔ∏è Image Classification with PyTorch | MLOps using ZenML
This work implements a Machine Learning (ML) workflow and deployment for an image classification model built using PyTorch and trained on CIFAR-100 dataset. The project implements a complete MLOps workflow with **ZenML** for orchestration, **MLFlow** for Experiment Tracking, **Streamlit** for UI, **FastAPI** for backend services, and connects to a deployed model on an MLOps server for inference. The goal is to demonstrate how to integrate machine learning pipelines with MLOps tools and serve a deep learning model using a modern full-stack setup.

<p align="center">
  <img src="screen.jpg" alt="screen.jpg"><br>
</p>


# üõ†Ô∏è Technologies Used
- **PyTorch**: Deep learning framework for building the CNN model for classification.
- **ZenML**: MLOps framework for creating reproducible ML pipelines.
- **MLFlow**: For model logging and tracking (integrated via ZenML).
- **FastAPI**: Backend API service for handling inference requests.
- **Streamlit**: Frontend interface for user interactions.
- **Conda**: Used to manage the project‚Äôs virtual environment and dependencies.

## ü´ï Project Overview

<p align="center">
	<img src="mlflow_classifier.png" alt="classifier"  style="width:60%;"/>
</p>

The machine learning workflow involves loading and preprocessing the CIFAR-100 dataset, training and evaluating a CNN model, and then deploying the model to an MLOps server for serving predictions. A FastAPI service handles backend communication, while a Streamlit app provides a frontend interface for users to upload images and get classification results.

## üéØ MLOPs Pipeline

![pipeline.png](pipeline.png)

The implemented Machine Learning workflow consists of several key stages:
1. **Data Ingestion**: Load and preprocess (apply transformations) the CIFAR-100 dataset.
2. **DataLoader**: Fetch loader objects for ingested and processed data.
3. **Model Training**: Train a convolutional neural network (CNN) on the training dataset.
4. **Model Evaluation**: Evaluate the performance of the model on the training dataset.
6. **Model Deployment**: Deploy the model to a ZenML-based MLOps server if it meets the  for serving predictions.
7. **Inference Service**: Build a FastAPI service for communication between the frontend and backend.
8. **Frontend Interface**: Build a Streamlit app to provide a user-friendly interface for image uploads and classification results.


### üöÄ How to Run the Project

1. **Clone the repository**

   ```bash
   git clone https://github.com/supreetshm947/MLOps_ImageClassification.git
   cd MLOps_ImageClassification

2. **Create Conda Environment and Install Dependencies**

   ```bash
   conda create -n ENV_NAME python=3.10 -y
	conda activate ENV_NAME
	pip install -r requirements.txt

3. **Setting up Zenml**
   
   - Installing Dependencies
      ```bash
      make setup

   - Creating and registering experiment tracker, model deployer and stack 
      ```bash
      make create

4. **Starting Zenml Server**
   ```bash
   make start

5. **Training Pipeline**

   You can run the pipeline by specifying the `--config` flag, which can take one of the following options:
   
   - `"deploy"`: Train and deploy the model if it meets the specified accuracy threshold.
   - `"predict"`: Use the trained model to make predictions.
   - `"deploy_and_predict"`: Train, deploy, and then run predictions using the model.
   
   Additionally, you can set a `--min_accuracy` flag, which determines the minimum accuracy required for a trained model to be deployed on the MLflow server.

   Example usage to deploy a model only if its accuracy is greater than 40%:

   ```bash
   python run_deployment.py --config deploy --min_accuracy 0.40

6. Start FastAPI

	```bash
 	python classification_api.py
 

7. **Start the Streamlit Frontend**

	Run the Streamlit app to interact with the model:
	
	```bash
	streamlit run streamlit_app.py
	
